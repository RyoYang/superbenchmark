version: v0.7
superbench:
  enable:
  - ib-traffic:pair-wise
  - nccl-bw:pair-wise
  # - model-benchmarks:stress
  monitor:
    enable: true
    sample_duration: 1
    sample_interval: 10
  var:
    nccl_env: &nccl_env
      NCCL_IB_PCI_RELAXED_ORDERING: '1'
      NCCL_NET_GDR_LEVEL: '5'
      NCCL_TOPO_FILE: /opt/microsoft/ndv4-topo.xml
      NCCL_DEBUG: WARN
    nccl_all_nodes_pattern: &nccl_all_nodes_pattern
      type: all-nodes
      mpi_pattern: true
    nccl_pair_wise_pattern: &nccl_pair_wise_pattern
      type: pair-wise
      mpi_pattern: true
    nccl_k_batch_pattern: &nccl_k_batch_pattern
      type: k-batch
      mpi_pattern: true
      batch: 3
    nccl_topo_aware_pattern: &nccl_topo_aware_pattern
      type: topo-aware
      mpi_pattern: true
      ibnetdiscover: /tmp
      min_dist: 2
      max_dist: 6
    nccl_allreduce_config: &nccl_allreduce_config
      timeout: 1200
      modes:
      - name: mpi
        proc_num: 8
        node_num: all
        pattern:
          <<: *nccl_all_nodes_pattern
        env:
          <<: *nccl_env
      parameters:
        # run_count: 5
        minbytes: 1K
        maxbytes: 16G
        stepfactor: 2
        check: 1
        warmup_iters: 20
        iters: 100
    torch_dist_config: &torch_dist_config
      timeout: 3600
      modes:
      - name: torch.distributed
        proc_num: 8
        node_num: all
        env:
          <<: *nccl_env
      frameworks: [pytorch]
      models: [gpt2-large]
      parameters:
        # run_count: 5
        duration: 1800
        num_warmup: 64
        num_steps: -100
        sample_count: 8192
        batch_size: 8
        seq_len: 224
        precision: [float32]
        model_action: [train]
        pin_memory: yes
  benchmarks:
    ib-traffic:pair-wise:
      modes:
      - name: mpi
        proc_num: 8
        node_num: all
        mca:
          routed: direct
      parameters:
        msg_size: 8388608
        bidirectional: yes
        ib_dev: mlx5_ib\$LOCAL_RANK
        gpu_dev: \$LOCAL_RANK
        numa_dev: \$((LOCAL_RANK/2))
    nccl-bw:pair-wise:
      <<: *nccl_allreduce_config
    # model benchmark - training
    model-benchmarks:stress:
      <<: *torch_dist_config